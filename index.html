
<!DOCTYPE html>
<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-137059345-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-137059345-1');
</script>


<style type="text/css">
      body {
        font-size: 1.13em;
        font-family: "Karla", "Helvetica", sans-serif;
        padding: 4em 1em;
        width:800px;
        margin-left:auto;
        margin-right:auto;
      }
      h1, h2, h3 {
        font-family: "Libre Baskerville", serif;
      }
      h2 {
        padding-top: 0.5em;
      }
      p {
        font-size: 1.13em;
      }
</style>

<title>Ainesh Bakshi</title>
</head>
<body>

<table cellpadding="20">
<tr>
<td>
<img src="pic.jpg" width="300" height="420"> 
</td>
<td>
<font size="5"><strong>Ainesh Bakshi</strong></font>
<br><br>Email: ainesh (at) mit (dot) edu<br><br>
Office: 2-174 <br><br>
</td>
</tr>
</table>
<p>

I am currently a postdoc in the Computer Science and Mathematics departments at MIT, where I collaborate closely with <a href="https://people.csail.mit.edu/moitra/">Ankur Moitra</a>, <a href="https://www.samuelbhopkins.com/">Sam Hopkins</a> and <a href="https://people.csail.mit.edu/indyk/">Piotr Indyk</a>. I am broadly interested in Theoretical Computer Science and my current research interests are robust algorithm design, the sum-of-squares convex programming hierarchy, randomized numerical linear algebra and high dimensional probability. </br></br>


I recently finished my PhD at Carnegie Mellon University, where I was extremely fortunate to be co-advised by <a href="https://www.cs.cmu.edu/~praveshk/">Pravesh Kothari</a> and <a href="http://www.cs.cmu.edu/~dwoodruf/">David Woodruff</a>. During the summer of 2021, I interned with <a href="https://home.ttic.edu/~madhurt/">Madhur Tulsiani</a> and <a href="https://home.ttic.edu/~yury/">Yury Makarychev</a> at Toyota Technological Institute-Chicago and in summer 2020, I interned with <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-klclarks">Ken Clarkson</a> at IBM Almaden.</br></br> 

Even earlier, I was an undergrad at Rutgers, New Brunswick, where I had the pleasure of working with <a href="https://www.cs.rutgers.edu/~farach/">Martin Farach-Colton</a>
and <a href="https://www.cs.rutgers.edu/~pa336/">Pranjal Awasthi</a>. 

</p>
<hr />
<h3>Dissertation</h3>
<div align="left">
<ul>

<li><i>Algorithms for Learning Latent Models: Establishing Tractability to Approaching Optimality</i><br>
PhD Thesis <a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/home/ftp/2022/CMU-CS-22-146.pdf">[pdf]</a><br>
Committee: <a href="https://www.cs.cmu.edu/~praveshk/">Pravesh Kothari</a>, <a href="http://www.cs.cmu.edu/~dwoodruf/">David Woodruff</a>, <a href="http://www.cs.cmu.edu/~odonnell/">Ryan O'Donnell</a>, <a href="https://www.boazbarak.org/">Boaz Barak</a>.
<br><br>
</ul>
</div>


</p>
<hr />
<h3>Publications</h3>
<div align="left">
<ul>



<!-- <li><i>A New Approach to Learning a Linear Dynamical System</i><br>
Ainesh Bakshi, Allen Liu, Ankur Moitra, Morris Yau<br>
Preprint <a href="https://arxiv.org/abs/2212.00642">[arXiv]</a>.
<br><br>

<li><i>A Classical Singular Value Transform for Quantum Machine Learning</i><br>
Ainesh Bakshi, Ewin Tang<br>
Preprint <a href="https://arxiv.org/abs/2212.00642">[arXiv]</a>.
<br><br> -->

<li><i>Sub-Quadratic Algorithms for Kernel Matrices via Kernel Density Estimation</i><br>
Ainesh Bakshi, Piotr Indyk, Praneeth Kacham, Sandeep Silwal and Samson Zhou<br>
ICLR 2023 <a href="https://arxiv.org/abs/2212.00642">[arXiv]</a>.
<br><br>

<li><i>Low-Rank Approximation with 1/epsilon^(1/3) Matrix-Vector Products</i><br>
Ainesh Bakshi, Ken Clarkson and David Woodruff<br>
STOC 2022 <a href="https://arxiv.org/abs/2202.05120">[arXiv]</a>
<a href="https://www.youtube.com/watch?v=fDhg6NuoQoM&list=PL_PV4lh5RnN4feN-AqQPbzXtQmgn3dZLU&index=5&ab_channel=CMUTheory">[Long Talk @ CMU]</a> <a href="https://www.youtube.com/watch?v=q_4ijhdHxO8&t=2s&ab_channel=SIGACTEC">[Talk @ STOC]</a>. 
<br><br>


<li><i>Robustly Learning Mixtures of k Arbitrary Gaussians</i><br>
Ainesh Bakshi, Ilias Diakonikolas, He Jia, Daniel Kane, Pravesh Kothari and Santosh Vempala<br>
STOC 2022 <a href="https://arxiv.org/abs/2012.02119">[arXiv]</a> <a href="https://www.youtube.com/watch?v=g4zwlESlGqs&t=109s&ab_channel=AdvancedAlgorithms">[Long Talk @ Northwestern]</a> <a href="https://www.youtube.com/watch?v=7gs_F9X9wPg&ab_channel=SIGACTEC">[Talk @ STOC]</a>. <br><br>

<li><i>Robust Linear Regression: Optimal Rates in Polynomial Time</i><br>
Ainesh Bakshi, Adarsh Prasad<br>
STOC 2021 <a href="http://arxiv.org/abs/2007.01394">[arXiv]</a> <a href="https://www.youtube.com/watch?v=avDqZpp7aQA&t=333s&ab_channel=SIGACTEC">[Talk @ STOC]</a>. <br><br>

<li><i>Learning a Latent Simplex in Input Sparsity Time</i><br>
Ainesh Bakshi, Chiranjib Bhattacharyya, Ravi Kannan, David Woodruff and Samson Zhou<br>
ICLR 2021, Selected for Spotlight Presentation <a href="https://arxiv.org/abs/2105.08005">[arXiv]</a>. <br><br>

<li><i>List-Decodable Subspace Recovery: Dimension Independent Error in Polynomial Time</i><br>
Ainesh Bakshi, Pravesh Kothari<br>
SODA 2021 <a href="https://arxiv.org/abs/2002.05139">[arXiv]</a>. <br><br>

<li><i>Testing Positive Semi-Definiteness via Random Submatrices</i><br>
Ainesh Bakshi, Nadiia Chepurko, Rajesh Jayaram<br>
FOCS 2020 <a href="https://arxiv.org/abs/2005.06441">[arXiv]</a>.<br><br>


<li><i>Outlier-Robust Clustering of Non-spherical Mixtures</i><br>
Ainesh Bakshi, Pravesh Kothari<br>
FOCS 2020 <a href="https://arxiv.org/abs/2005.02970">[arXiv]</a>,  <a href="https://www.youtube.com/watch?v=gpbm7ypzRBs&ab_channel=IEEEFOCS%3AFoundationsofComputerScience">[Joint Talk @ FOCS'20]</a>, <a href="https://www.youtube.com/watch?v=LROPBjuAKHQ&feature=youtu.be&ab_channel=MadhurTulsiani">[Long Talk @ TTI-C]</a> <br>
Conference version to be merged with <a href="https://arxiv.org/abs/2005.06417">this</a> paper. <br><br>


<li><i>Robust and Sample Optimal Algorithms for PSD Low Rank Approximation</i><br>
Ainesh Bakshi, Nadiia Chepurko, David Woodruff<br>
FOCS 2020 <a href="https://arxiv.org/abs/1912.04177">[arXiv]</a>,  <a href="https://www.youtube.com/watch?v=iv4H1-7R_zU&t=8s">[Talk @ WOLA'20]</a>,  <a href="https://www.youtube.com/watch?v=MUbWxZin8cc&t=1s&ab_channel=IEEEFOCS%3AFoundationsofComputerScience">[Joint Talk @ FOCS'20]</a>. <br><br>


<li><i>Weighted Maximum Independent Set of Geometric Objects in Turnstile Streams</i><br>
Ainesh Bakshi, Nadiia Chepurko, David Woodruff<br>
APPROX 2020 <a href="https://arxiv.org/abs/1902.10328">[arXiv]</a> <a href="https://www.youtube.com/watch?v=rMPkawe_09Q&t=1s">[Talk @ Approx]</a>. <br><br>

<li><i>Robust Communication-Optimal Distributed Clustering Algorithms</i><br>
Pranjal Awasthi, Ainesh Bakshi, Nina Balcan, Colin White, David Woodruff<br>
ICALP 2019 <a href="https://arxiv.org/abs/1703.00830">[arXiv]</a>. <br><br>


<li><i>Learning Two Layer Rectified Neural Networks in Polynomial Time</i><br>
Ainesh Bakshi, Rajesh Jayaram,
David Woodruff<br>
COLT 2019 <a href="https://arxiv.org/abs/1811.01885">[arXiv]</a>. <br><br>



<li><i>Sublinear Time Low-Rank Approximation of Distance Matrices</i><br>
Ainesh Bakshi,
David Woodruff<br>
NeurIPS 2018, Selected for Spotlight Presentation <a href="https://arxiv.org/abs/1809.06986">[arXiv]</a>, <a href="https://www.youtube.com/watch?v=DwFTzrMt1DY">[Talk @ CMU TL]</a>. <br><br>

</ul>
</div>


</p>
<hr />
<h3>Undergraduate Work</h3>
<div align="left">
<ul>

<li><a href="https://www.usenix.org/publications/login/summer2017/conway">
"How to Fragment your File System"</a><br>
A. Conway,
A. Bakshi,
Y. Jiao,
Y. Zhan,
M. Bender,
W. Jannen,
R. Johnson,
B. Kuzmaul,
D. Porter,
J. Yuan,
M. Farach-Colton<br>
;login: magazine, vol. 42(2), 2017.<br><br>

<li><a href="https://www.usenix.org/conference/fast17/technical-sessions/presentation/conway">
"File Systems fated for Senescence? Nonsense, Says Science!"</a><br>
A. Conway,
A. Bakshi,
Y. Jiao,
Y. Zhan,
M. Bender,
W. Jannen,
R. Johnson,
B. Kuzmaul,
D. Porter,
J. Yuan,
M. Farach-Colton<br>
Proceedings of the 15th USENIX Conference on File and Storage Technologies (FAST '17), Santa Clara, CA, February 2017.<br><br>

<!-- <li><a href="pubs/Optimization.pdf">
"Non Dominated Sorting Genetic Algorithm for Chance Constrained Supplier Selection Model with Volume Discounts"</a><br>
R. Agarwal,
A. Bakshi<br>
ACIIDS, Lecture Notes in Computer Science pp. 465–474, Apr 2014.<br><br>

<li><a href="pubs/Classification.pdf">
"A Novel Feature Selection and Extraction Technique for Classification"</a><br>
K. Goel,
R. Vohra
A. Bakshi<br>
ICFHR 2014, pp. 104-109.<br><br>

<li><a href="pubs/PathPlanning.pdf">
"Autonomous Robot Navigation: Path Planning on a Detail-Preserving Reduced-Complexity Representation of 3D Point Clouds"</a><br>
R. Sant,
N. Kulkarni,
A. Bakshi,
K. Goel,
S. Kapur<br>
ICFHR 2014, pp. 104-109.<br><br>
 -->
</ul>
</div>

</p>
<hr />
<h3>Teaching</h3>
<div align="left">
<ul>

  <li> TA for <a href="http://www.cs.cmu.edu/~odonnell/toolkit20/"> CS 15-751 : TCS Toolkit </a><br>
  by <a href="http://www.cs.cmu.edu/~odonnell/">Ryan O'Donnell</a> <br><br>

  <li> TA for <a href="https://www.cs.cmu.edu/~15451-s19/"> CS 15-451/651 : Algorithms </a><br>
  by <a href="http://www.cs.cmu.edu/~anupamg/">Anupam Gupta</a> and <a href="http://www.cs.cmu.edu/~dwoodruf/">David Woodruff</a> <br><br>

</ul>
</div>



</body>
</html>
